//! Whisper API è°ƒç”¨æ¨¡å—
//! 
//! æ”¯æŒ OpenAIã€Groq å’Œé˜¿é‡Œäº‘çš„è¯­éŸ³è¯†åˆ« API

use reqwest::blocking::multipart;
use serde::Deserialize;
use std::env;
use std::fs::File;
use std::io::Read;

#[derive(Debug, Deserialize)]
struct TranscriptionResponse {
    text: String,
}

/// é˜¿é‡Œäº‘ OpenAI å…¼å®¹æ ¼å¼å“åº”
#[derive(Debug, Deserialize)]
struct AliyunChatResponse {
    choices: Option<Vec<AliyunChoice>>,
    error: Option<AliyunError>,
}

#[derive(Debug, Deserialize)]
struct AliyunChoice {
    message: AliyunMessage,
}

#[derive(Debug, Deserialize)]
struct AliyunMessage {
    content: String,
}

#[derive(Debug, Deserialize)]
struct AliyunError {
    message: String,
}

/// æµ‹è¯• API è°ƒç”¨
pub fn test_api() {
    // åŠ è½½ .env æ–‡ä»¶
    dotenv::dotenv().ok();
    
    println!("ğŸŒ API æµ‹è¯•");
    println!("============");
    println!("");
    
    // æ£€æŸ¥å¯ç”¨çš„ API Key
    let has_openrouter = env::var("OPENROUTER_API_KEY").is_ok();
    let has_aliyun = env::var("ALIYUN_API_KEY").is_ok();
    let has_groq = env::var("GROQ_API_KEY").is_ok();
    let has_openai = env::var("OPENAI_API_KEY").is_ok();
    
    println!("æ£€æµ‹åˆ°çš„ API Key:");
    println!("  OpenRouter: {}", if has_openrouter { "âœ…" } else { "âŒ" });
    println!("  é˜¿é‡Œäº‘:     {}", if has_aliyun { "âœ…" } else { "âŒ" });
    println!("  Groq:       {}", if has_groq { "âœ…" } else { "âŒ" });
    println!("  OpenAI:     {}", if has_openai { "âœ…" } else { "âŒ" });
    println!("");
    
    if !has_openrouter && !has_aliyun && !has_groq && !has_openai {
        println!("âŒ æœªæ‰¾åˆ°ä»»ä½• API Key");
        println!("");
        println!("è¯·åœ¨ .env æ–‡ä»¶ä¸­è®¾ç½®:");
        println!("  OPENROUTER_API_KEY=your_key # OpenRouter");
        println!("  ALIYUN_API_KEY=your_key     # é˜¿é‡Œäº‘ç™¾ç‚¼");
        println!("  GROQ_API_KEY=your_key       # Groq");
        println!("  OPENAI_API_KEY=your_key     # OpenAI");
        return;
    }
    
    // æŸ¥æ‰¾æµ‹è¯•éŸ³é¢‘æ–‡ä»¶
    let recent_recording = find_recent_recording();
    
    match recent_recording {
        Some(file) => {
            println!("ğŸ“ ä½¿ç”¨æµ‹è¯•æ–‡ä»¶: {}", file);
            println!("ğŸ”„ è°ƒç”¨ API ä¸­...");
            println!("");
            
            match transcribe_file(&file) {
                Ok(text) => {
                    println!("âœ… è¯†åˆ«æˆåŠŸï¼");
                    println!("ğŸ“ ç»“æœ: {}", text);
                }
                Err(e) => {
                    println!("âŒ è°ƒç”¨å¤±è´¥: {}", e);
                }
            }
        }
        None => {
            println!("ğŸ’¡ æ²¡æœ‰æµ‹è¯•éŸ³é¢‘æ–‡ä»¶ï¼Œè¯·å…ˆè¿è¡Œå½•éŸ³æµ‹è¯•:");
            println!("   cargo run -- record");
        }
    }
}

/// æŸ¥æ‰¾æœ€è¿‘çš„å½•éŸ³æ–‡ä»¶
fn find_recent_recording() -> Option<String> {
    let entries = std::fs::read_dir("/tmp").ok()?;
    
    entries
        .filter_map(|e| e.ok())
        .filter(|e| {
            e.file_name()
                .to_string_lossy()
                .starts_with("aitotype_recording_")
        })
        .max_by_key(|e| e.metadata().ok().and_then(|m| m.modified().ok()))
        .map(|e| e.path().to_string_lossy().to_string())
}

/// è½¬å½•éŸ³é¢‘æ–‡ä»¶
/// 
/// è‡ªåŠ¨é€‰æ‹©å¯ç”¨çš„ API æä¾›å•†
/// OpenRouter å“åº”æ ¼å¼ (æ ‡å‡† OpenAI æ ¼å¼)
#[derive(Debug, Deserialize)]
struct OpenRouterResponse {
    choices: Vec<OpenRouterChoice>,
    error: Option<OpenRouterError>,
}

#[derive(Debug, Deserialize)]
struct OpenRouterChoice {
    message: OpenRouterMessage,
}

#[derive(Debug, Deserialize)]
struct OpenRouterMessage {
    content: Option<String>,
}

#[derive(Debug, Deserialize)]
struct OpenRouterError {
    message: String,
}

/// è½¬å½•éŸ³é¢‘æ–‡ä»¶
/// 
/// è‡ªåŠ¨é€‰æ‹©å¯ç”¨çš„ API æä¾›å•†
pub fn transcribe_file(file_path: &str) -> Result<String, String> {
    // åŠ è½½ .env æ–‡ä»¶
    dotenv::dotenv().ok();
    
    // ä¼˜å…ˆä½¿ç”¨ OpenRouter (Gemini 3 Flash Preview)
    if let Ok(api_key) = env::var("OPENROUTER_API_KEY") {
        println!("ğŸ“¡ ä½¿ç”¨ OpenRouter API (Gemini 3 Flash Preview)...");
        // å…ˆå°è¯•å¤šæ¨¡æ€ç›´æ¥è°ƒç”¨ï¼Œå¦‚æœå¤±è´¥åˆ™å›é€€ï¼ˆç›®å‰å‡è®¾æ”¯æŒï¼‰
        return transcribe_with_openrouter(file_path, &api_key);
    }

    // å…¶æ¬¡ä½¿ç”¨é˜¿é‡Œäº‘ï¼ˆå›½å†…è®¿é—®å¿«ï¼‰- ä½¿ç”¨ Qwen2-Audio æ¨¡å‹
    if let Ok(api_key) = env::var("ALIYUN_API_KEY") {
        println!("ğŸ“¡ ä½¿ç”¨é˜¿é‡Œäº‘ DashScope Qwen2-Audio API...");
        return transcribe_with_aliyun_qwen_audio(file_path, &api_key);
    }
    
    // å…¶æ¬¡ä½¿ç”¨ Groqï¼ˆé€Ÿåº¦å¿«ã€ä¾¿å®œï¼‰
    if let Ok(api_key) = env::var("GROQ_API_KEY") {
        println!("ğŸ“¡ ä½¿ç”¨ Groq API...");
        return transcribe_with_openai_compatible(
            file_path, 
            &api_key,
            "https://api.groq.com/openai/v1/audio/transcriptions",
            "whisper-large-v3-turbo"
        );
    }
    
    // æœ€åä½¿ç”¨ OpenAI
    if let Ok(api_key) = env::var("OPENAI_API_KEY") {
        println!("ğŸ“¡ ä½¿ç”¨ OpenAI API...");
        return transcribe_with_openai_compatible(
            file_path,
            &api_key,
            "https://api.openai.com/v1/audio/transcriptions",
            "whisper-1"
        );
    }
    
    Err("æœªè®¾ç½®ä»»ä½• API Key (OPENROUTER_API_KEY, ALIYUN_API_KEY, GROQ_API_KEY æˆ– OPENAI_API_KEY)".to_string())
}

/// ä½¿ç”¨ OpenRouter è½¬å½• (æ”¯æŒ Gemini å¤šæ¨¡æ€)
fn transcribe_with_openrouter(file_path: &str, api_key: &str) -> Result<String, String> {
    // è¯»å–éŸ³é¢‘æ–‡ä»¶
    let mut file = File::open(file_path)
        .map_err(|e| format!("æ‰“å¼€æ–‡ä»¶å¤±è´¥: {:?}", e))?;
    
    let mut buffer = Vec::new();
    file.read_to_end(&mut buffer)
        .map_err(|e| format!("è¯»å–æ–‡ä»¶å¤±è´¥: {:?}", e))?;
    
    // ä½¿ç”¨ base64 ç¼–ç éŸ³é¢‘
    use base64::{Engine as _, engine::general_purpose::STANDARD};
    let audio_base64 = STANDARD.encode(&buffer);
    
    // æ ¹æ® OpenRouter å®˜æ–¹æ–‡æ¡£ï¼Œä½¿ç”¨ input_audio ç±»å‹ä¼ é€’éŸ³é¢‘
    // data æ˜¯çº¯ base64 å­—ç¬¦ä¸²ï¼ˆä¸å¸¦ data:audio/wav;base64, å‰ç¼€ï¼‰
    // format æŒ‡å®šéŸ³é¢‘æ ¼å¼
    let request_body = serde_json::json!({
        "model": "google/gemini-3-flash-preview",
        "messages": [
            {
                "role": "user",
                "content": [
                    {
                        "type": "text",
                        "text": "è¯·ç²¾å‡†è½¬å½•è¿™æ®µéŸ³é¢‘å†…å®¹ã€‚ä¿æŒåŸä¹‰ï¼Œä¸è¦ç¿»è¯‘ï¼Œå¦‚æœæ˜¯ä¸­æ–‡å°±ç›´æ¥è¾“å‡ºä¸­æ–‡ã€‚åªè¾“å‡ºè½¬å½•æ–‡å­—ï¼Œä¸è¦è¾“å‡ºä»»ä½•è§£é‡Šã€‚"
                    },
                    {
                        "type": "input_audio",
                        "input_audio": {
                            "data": audio_base64,
                            "format": "wav"
                        }
                    }
                ]
            }
        ]
    });

    // å‘é€è¯·æ±‚
    let client = reqwest::blocking::Client::builder()
        .timeout(std::time::Duration::from_secs(120))
        .build()
        .map_err(|e| format!("åˆ›å»ºå®¢æˆ·ç«¯å¤±è´¥: {:?}", e))?;
        
    let response = client
        .post("https://openrouter.ai/api/v1/chat/completions")
        .header("Authorization", format!("Bearer {}", api_key))
        .header("Content-Type", "application/json")
        // æ·»åŠ  Referer ä¸ºäº† OpenRouter ç»Ÿè®¡
        .header("HTTP-Referer", "https://github.com/aitotype") 
        .header("X-Title", "AitoType")
        .json(&request_body) 
        .send()
        .map_err(|e| format!("è¯·æ±‚å¤±è´¥: {:?}", e))?;
    
    if !response.status().is_success() {
        let status = response.status();
        let error_text = response.text().unwrap_or_default();
        return Err(format!("API è¿”å›é”™è¯¯ {}: {}", status, error_text));
    }
    
    let result: OpenRouterResponse = response.json()
        .map_err(|e| format!("è§£æå“åº”å¤±è´¥: {:?}", e))?;
        
    if let Some(error) = result.error {
        return Err(format!("OpenRouter é”™è¯¯: {}", error.message));
    }
    
    if let Some(choice) = result.choices.first() {
        if let Some(content) = &choice.message.content {
            return Ok(content.clone());
        }
    }
    
    Err("OpenRouter æœªè¿”å›å†…å®¹".to_string())
}

/// é˜¿é‡Œäº‘ DashScope åŸç”Ÿå“åº”æ ¼å¼
#[derive(Debug, Deserialize)]
struct DashScopeResponse {
    output: Option<DashScopeOutput>,
    message: Option<String>,
    code: Option<String>,
}

#[derive(Debug, Deserialize)]
struct DashScopeOutput {
    choices: Option<Vec<DashScopeChoice>>,
}

#[derive(Debug, Deserialize)]
struct DashScopeChoice {
    message: DashScopeMessage,
}

#[derive(Debug, Deserialize)]
struct DashScopeMessage {
    content: Option<serde_json::Value>, 
}

/// ä½¿ç”¨é˜¿é‡Œäº‘ Qwen2-Audio æ¨¡å‹è½¬å½• (DashScope åŸç”Ÿ API)
/// 
/// ç›¸æ¯”äº OpenAI å…¼å®¹æ¥å£ï¼ŒDashScope åŸç”Ÿæ¥å£å¯¹å¤šæ¨¡æ€æ”¯æŒæ›´å¥½
fn transcribe_with_aliyun_qwen_audio(file_path: &str, api_key: &str) -> Result<String, String> {
    // è¯»å–éŸ³é¢‘æ–‡ä»¶
    let mut file = File::open(file_path)
        .map_err(|e| format!("æ‰“å¼€æ–‡ä»¶å¤±è´¥: {:?}", e))?;
    
    let mut buffer = Vec::new();
    file.read_to_end(&mut buffer)
        .map_err(|e| format!("è¯»å–æ–‡ä»¶å¤±è´¥: {:?}", e))?;
    
    // ä½¿ç”¨ base64 ç¼–ç éŸ³é¢‘
    use base64::{Engine as _, engine::general_purpose::STANDARD};
    let audio_base64 = STANDARD.encode(&buffer);
    
    // æ„å»º DashScope åŸç”Ÿè¯·æ±‚ä½“ - Multimodal Generation
    let request_body = serde_json::json!({
        "model": "qwen-audio-turbo",
        "input": {
            "messages": [
                {
                    "role": "user",
                    "content": [
                        { "audio": format!("data:audio/wav;base64,{}", audio_base64) },
                        { "text": "è¯·å°†è¿™æ®µéŸ³é¢‘å†…å®¹è½¬å†™ä¸ºæ–‡å­—ï¼Œä¸è¦æ·»åŠ ä»»ä½•æ ‡ç‚¹ç¬¦å·ä»¥å¤–çš„è§£é‡Šæ€§æ–‡å­—ã€‚" }
                    ]
                }
            ]
        },
        "parameters": {}
    });
    
    // å‘é€è¯·æ±‚åˆ°é˜¿é‡Œäº‘ DashScope
    let client = reqwest::blocking::Client::builder()
        .timeout(std::time::Duration::from_secs(60))
        .build()
        .map_err(|e| format!("åˆ›å»º HTTP å®¢æˆ·ç«¯å¤±è´¥: {:?}", e))?;
    
    let response = client
        .post("https://dashscope.aliyuncs.com/api/v1/services/aigc/multimodal-generation/generation")
        .header("Authorization", format!("Bearer {}", api_key))
        .header("Content-Type", "application/json")
        .json(&request_body)
        .send()
        .map_err(|e| format!("è¯·æ±‚å¤±è´¥: {:?}", e))?;
    
    if !response.status().is_success() {
        let status = response.status();
        let error_text = response.text().unwrap_or_default();
        return Err(format!("API è¿”å›é”™è¯¯ {}: {}", status, error_text));
    }
    
    let result: DashScopeResponse = response.json()
        .map_err(|e| format!("è§£æå“åº”å¤±è´¥: {:?}", e))?;
    
    if let Some(code) = result.code {
        return Err(format!("API é”™è¯¯ [{}]: {}", code, result.message.unwrap_or_default()));
    }
    
    if let Some(output) = result.output {
        if let Some(choices) = output.choices {
            if let Some(choice) = choices.first() {
                if let Some(content_val) = &choice.message.content {
                   // content å¯èƒ½æ˜¯ string æˆ– list
                   if let Some(s) = content_val.as_str() {
                       return Ok(s.to_string());
                   }
                   if let Some(arr) = content_val.as_array() {
                       // æå– list ä¸­çš„ text
                       let mut text = String::new();
                       for item in arr {
                           if let Some(t) = item.get("text").and_then(|v| v.as_str()) {
                               text.push_str(t);
                           }
                       }
                       if !text.is_empty() {
                           return Ok(text);
                       }
                   }
                   return Ok(content_val.to_string());
                }
            }
        }
    }
    
    Err("æœªè·å–åˆ°è½¬å½•ç»“æœ".to_string())
}

/// ä½¿ç”¨ OpenAI å…¼å®¹ API è½¬å½• (OpenAI, Groq ç­‰)
fn transcribe_with_openai_compatible(
    file_path: &str, 
    api_key: &str,
    base_url: &str,
    model: &str
) -> Result<String, String> {
    // è¯»å–æ–‡ä»¶
    let mut file = File::open(file_path)
        .map_err(|e| format!("æ‰“å¼€æ–‡ä»¶å¤±è´¥: {:?}", e))?;
    
    let mut buffer = Vec::new();
    file.read_to_end(&mut buffer)
        .map_err(|e| format!("è¯»å–æ–‡ä»¶å¤±è´¥: {:?}", e))?;
    
    // æ„å»º multipart è¯·æ±‚
    let file_part = multipart::Part::bytes(buffer)
        .file_name("audio.wav")
        .mime_str("audio/wav")
        .map_err(|e| format!("åˆ›å»ºè¯·æ±‚å¤±è´¥: {:?}", e))?;
    
    let form = multipart::Form::new()
        .part("file", file_part)
        .text("model", model.to_string());
    
    // å‘é€è¯·æ±‚
    let client = reqwest::blocking::Client::new();
    let response = client
        .post(base_url)
        .header("Authorization", format!("Bearer {}", api_key))
        .multipart(form)
        .send()
        .map_err(|e| format!("è¯·æ±‚å¤±è´¥: {:?}", e))?;
    
    if !response.status().is_success() {
        let status = response.status();
        let error_text = response.text().unwrap_or_default();
        return Err(format!("API è¿”å›é”™è¯¯ {}: {}", status, error_text));
    }
    
    let result: TranscriptionResponse = response.json()
        .map_err(|e| format!("è§£æå“åº”å¤±è´¥: {:?}", e))?;
    
    Ok(result.text)
}
